# 將 Whisper 離線模型改造為串流模式

了解了兩種基礎架構後，我們的核心問題浮現：如何將 Whisper 這樣一個高品質的**離線模型**，改造成能夠**即時反應**的串流模型？以下是幾種主流的技術路線。

## 路線 A：偽串流 (Pseudo-streaming)

這是最簡單、工程上最快實現的方案。

- **思路**: 維持原模型不改動結構，通過「滑動視窗 + 重疊上下文 + 穩定化規則」來模擬串流效果。
- **典型實現**: [whisper-streaming](https://github.com/ufal/whisper-streaming) 專案就是此路線的優秀開源實現。
- **核心技術**:
  - **切片策略**: 將音訊流切分成固定長度的塊（chunk），每次送入最近 N 秒的上下文 + 新的音訊塊進行辨識。
  - **快取優化**: 保留 Encoder/Decoder 的 KV 快取，避免每次都從頭對整段上下文進行重算。
  - **穩定化**: 對連續幾次解碼結果中重疊的部分進行一致性檢查（如投票機制），以減少文字的「閃爍」和「回退」。
  - **端點偵測**: 依賴外部 VAD 來決定何時切分和送入模型。
- **優缺點**:
  - **優點**: 實現相對簡單，可以快速上線。
  - **缺點**: 延遲較高（通常 >500ms），且由於是「重算+回寫」的模式，在長句中文字會有可見的回溯修正，體驗並非最佳。
- **適用場景**: 需要快速實現一個「可用」的串流功能，且能接受其非即時、會修正的特性。

## 路線 B：Whisper Encoder + CTC 頭

這是中等難度的方案，需要對模型進行微調（fine-tuning），以實現真正的串流。

- **思路**: 拋棄 Whisper 原本的解碼器（Decoder），將其強大的編碼器（Encoder）當作一個聲學特徵提取器，然後在其頂部接上一個輕量的 CTC 解碼頭。
- **相關研究**: Hugging Face 的 [Distil-Whisper](https://huggingface.co/distil-whisper/distil-large-v2) 專案雖然本身是離線模型，但它成功驗證了「僅使用 Encoder + CTC」這條技術路線的可行性，為串流改造提供了重要參考。
- **核心技術**:
  - **模型改造**:
    1. **(串流改造關鍵)** 將 Encoder 的注意力機制改為有限右視野（Chunkwise-Attention），並將絕對位置編碼替換為相對位置編碼，以解除 30 秒的輸入限制。
    2. 在 Encoder 輸出後接一個線性層，用於 CTC 解碼。
- **訓練策略**: 使用 CTC 損失函數對這個新模型進行微調。可以選擇性地使用原 Whisper 模型的輸出作為「老師」，進行知識蒸餾，以保留其一部分高品質的辨識能力。
- **優缺點**:
  - **優點**: 能實現較低延遲（~300-800ms）的真串流，且輸出穩定，不會回退。
  - **缺點**: 需要投入訓練資源和數據進行微調。模型的最終品質依賴於訓練數據和策略。
- **適用場景**: 願意投入資源進行模型微調，追求穩定、低延遲的真串流體驗。

## 路線 C：Whisper Encoder + RNN-T 頭

這是最高難度、但潛在效果最好的方案。

- **思路**: 同樣改造 Whisper 的 Encoder，但換上一個更先進的 Transducer (RNN-T) 解碼器，以達到最佳的串流體驗。
- **典型實現**: 業界知名的語音工具包 [ESPnet](https://github.com/espnet/espnet) 提供了將 Transformer Encoder 與 RNN-T 結合的完整訓練流程 (recipe)，是此路線的學術與工程標竿。
- **核心技術**:
  - **模型改造**: 將 Whisper 的解碼器替換為一個完整的 RNN-T 結構（包含 Predictor 和 Joiner）。
  - **訓練策略**: 使用 RNN-T 損失函數進行端到端的訓練。工程和訓練的複雜度是三者中最高的。
- **優缺點**:
  - **優點**: 能實現極致的串流體驗——延遲低、文字穩定、幾乎無回退，表現流暢。
  - **缺點**: 工程和訓練的複雜度、時間和資源投入都是最大的。
- **適用場景**: 追求產品級、最頂級的串流體驗，並有能力進行複雜的模型研發和訓練。

## 路線 D：組合式 Two-Pass 系統

它不改造 Whisper 模型本身，而是通過組合不同的現成模型來實現目標。

- **思路**: 結合一個**串流模型**（低延遲）和一個**離線模型**（高準確性），取其長處。
- **典型實現**: [Sherpa-ONNX](https://github.com/k2-fsa/sherpa-onnx) 框架本身就支援 Two-Pass 模式，允許第一階段使用輕量串流模型，第二階段再用高精度離線模型修正。
- **核心技術**:
  1. **第一階段**: 使用一個輕量的原生串流模型（如 Sherpa-ONNX 的 RNN-T）提供即時的初步辨識結果。
  2. **第二階段**: 在工程層面設計一套**觸發邏輯**（基於停頓、標點、句長等），當判斷一句話結束時，將緩存的完整音訊送入未經修改的 Whisper 模型，用其高品質的辨識結果去修正第一階段的輸出。
- **優缺點**:
  - **優點**: **無需訓練模型**，純工程實現，開發成本和資源投入遠低於路線 B 和 C。能同時兼顧低延遲（第一階段）和高準確性（第二階段）。
  - **缺點**: **觸發邏輯的設計是成敗的關鍵和核心難點**。如固定的觸發規則很難完美適應所有說話風格，容易在「太快」和「太慢」之間搖擺。
- **適用場景**: 希望在不投入大量 AI 訓練資源的前提下，快速搭建一個兼顧了低延遲和高準確性的高品質串流系統。

---

## 結論

每條路線都代表了一種在「開發成本」、「延遲體驗」和「辨識準確性」三者之間的權衡。

### 各路線比較總結

| 路線 | 核心思路 | 開發成本 | 延遲體驗 | 準確性 | 文字穩定性 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **A: 偽串流** | 滑動視窗 + 重算 | 低 | 較高 | 高 | 差 (會回退) |
| **B: Encoder+CTC** | 模型微調 | 中 | 中 | 中-高 | 好 (不回退) |
| **C: Encoder+RNN-T**| 模型微調 | 高 | 低 | 高 | 極好 (不回退) |
| **D: Two-Pass** | 雙模型組合 | 中 (純工程) | 低 (Pass 1) | 極高 (Pass 2) | 好 (最終修正) |
