# Streaming ASR 技術解析

Streaming ASR (即時語音辨識) 的核心挑戰在於，如何在音訊流尚未結束時，以盡可能低的延遲，持續地輸出辨識結果。

為了深入理解這個挑戰，本文將先從兩種基礎的 ASR 架構——**串流 (Streaming)** 與 **離線 (Offline)**——談起，釐清它們的根本差異。接著，我們將聚焦於核心議題：如何將以 Whisper 為代表的高品質**離線模型**，透過不同的技術路線進行改造，賦予其**串流**能力。

---

## 基礎 ASR 架構：串流 (Streaming) vs. 離線 (Offline)

### 1. 串流架構 (Streaming Architecture)

串流架構的核心是為了「即時性」而生，模型從結構上就被設計為逐塊處理音訊，持續輸出結果。

- **典型代表**: `RNN-T (Recurrent Neural Network Transducer)`, `CTC-based models`。
- **工作原理**: 模型逐幀或逐個音訊塊地處理數據。以 RNN-T 為例，它在每個時間步都會做出判斷：是輸出一個新的文字 token，還是等待接收更多的音訊。這種機制讓它天然地具備了 streaming 的能力。
- **優點**:
  - **極低延遲**: 理論上延遲可以做到與音訊幀同步，反應非常迅速。
  - **架構簡潔**: 單一模型即可完成任務。
- **缺點**:
  - **準確性瓶頸**: 由於模型在任何時間點都只能看到過去的音訊（缺乏未來上下文），其準確性通常無法與能看到完整音訊的離線模型媲美。
  - **斷句困難**: 需要額外的 VAD (語音活動偵測) 邏輯來判斷一句話的結束。
- **應用**: 對即時性要求極高的場景，也是更複雜系統（如 Two-Pass）的基礎元件。

### 2. 離線架構 (Offline Architecture)

離線架構以「準確性」為優先，其設計前提是模型能夠獲取到**完整的音訊片段**後再進行處理。

- **典型代表**: `Whisper`, `大多數基於 Transformer Encoder-Decoder 的模型`。
- **工作原理**: 利用一個獨立的 VAD (Voice Activity Detection) 模組來偵測語音的起點和終點。當偵測到一段靜默時，就將先前累積的完整音訊送入 ASR 模型進行一次性辨識。
- **優點**:
  - **準確性高**: 由於模型能看到完整的上下文資訊，辨識準確性通常是最高的。
  - **實現簡單**: 工程邏輯相對單純，只需「偵測 -> 緩存 -> 辨識」。
- **缺點**:
  - **高延遲**: 延遲非常高，因為必須等到一句話說完後的靜默期才能開始辨識，使用者會感覺到明顯的停頓。
  - **體驗不佳**: 沒有即時回饋，使用者無法在說話過程中看到文字輸出。
- **應用**: 語音檔轉錄、會議記錄整理等對準確性要求高、但對即時性要求不高的場景。

---

## 核心議題：將 Whisper 離線模型改造為串流模式

了解了兩種基礎架構後，我們的核心問題浮現：如何將 Whisper 這樣一個高品質的**離線模型**，改造成能夠**即時反應**的串流模型？以下是幾種主流的技術路線。

### 路線 A：偽串流 (Pseudo-streaming)

這是最簡單、工程上最快實現的方案。

- **思路**: 維持原模型不改動結構，通過「滑動視窗 + 重疊上下文 + 穩定化規則」來模擬串流效果。
- **典型實現**: [whisper-streaming](https://github.com/ufal/whisper-streaming) 專案就是此路線的優秀開源實現。
- **核心技術**:
  - **切片策略**: 將音訊流切分成固定長度的塊（chunk），每次送入最近 N 秒的上下文 + 新的音訊塊進行辨識。
  - **快取優化**: 保留 Encoder/Decoder 的 KV 快取，避免每次都從頭對整段上下文進行重算。
  - **穩定化**: 對連續幾次解碼結果中重疊的部分進行一致性檢查（如投票機制），以減少文字的「閃爍」和「回退」。
  - **端點偵測**: 依賴外部 VAD 來決定何時切分和送入模型。
- **優缺點**:
  - **優點**: 實現相對簡單，可以快速上線。
  - **缺點**: 延遲較高（通常 >500ms），且由於是「重算+回寫」的模式，在長句中文字會有可見的回溯修正，體驗並非最佳。
- **適用場景**: 需要快速實現一個「可用」的串流功能，且能接受其非即時、會修正的特性。

### 路線 B：Whisper Encoder + CTC 頭

這是中等難度的方案，需要對模型進行微調（fine-tuning），以實現真正的串流。

- **思路**: 拋棄 Whisper 原本的解碼器（Decoder），將其強大的編碼器（Encoder）當作一個聲學特徵提取器，然後在其頂部接上一個輕量的 CTC 解碼頭。
- **相關研究**: Hugging Face 的 [Distil-Whisper](https://huggingface.co/distil-whisper/distil-large-v2) 專案雖然本身是離線模型，但它成功驗證了「僅使用 Encoder + CTC」這條技術路線的可行性，為串流改造提供了重要參考。
- **核心技術**:
  - **模型改造**:
    1. **(串流改造關鍵)** 將 Encoder 的注意力機制改為有限右視野（Chunkwise-Attention），並將絕對位置編碼替換為相對位置編碼，以解除 30 秒的輸入限制。
    2. 在 Encoder 輸出後接一個線性層，用於 CTC 解碼。
- **訓練策略**: 使用 CTC 損失函數對這個新模型進行微調。可以選擇性地使用原 Whisper 模型的輸出作為「老師」，進行知識蒸餾，以保留其一部分高品質的辨識能力。
- **優缺點**:
  - **優點**: 能實現較低延遲（~300-800ms）的真串流，且輸出穩定，不會回退。
  - **缺點**: 需要投入訓練資源和數據進行微調。模型的最終品質依賴於訓練數據和策略。
- **適用場景**: 願意投入資源進行模型微調，追求穩定、低延遲的真串流體驗。

### 路線 C：Whisper Encoder + RNN-T 頭

這是最高難度、但潛在效果最好的方案。

- **思路**: 同樣改造 Whisper 的 Encoder，但換上一個更先進的 Transducer (RNN-T) 解碼器，以達到最佳的串流體驗。
- **典型實現**: 業界知名的語音工具包 [ESPnet](https://github.com/espnet/espnet) 提供了將 Transformer Encoder 與 RNN-T 結合的完整訓練流程 (recipe)，是此路線的學術與工程標竿。
- **核心技術**:
  - **模型改造**: 將 Whisper 的解碼器替換為一個完整的 RNN-T 結構（包含 Predictor 和 Joiner）。
  - **訓練策略**: 使用 RNN-T 損失函數進行端到端的訓練。工程和訓練的複雜度是三者中最高的。
- **優缺點**:
  - **優點**: 能實現極致的串流體驗——延遲低、文字穩定、幾乎無回退，表現流暢。
  - **缺點**: 工程和訓練的複雜度、時間和資源投入都是最大的。
- **適用場景**: 追求產品級、最頂級的串流體驗，並有能力進行複雜的模型研發和訓練。

### 路線 D：組合式 Two-Pass 系統

它不改造 Whisper 模型本身，而是通過組合不同的現成模型來實現目標。

- **思路**: 結合一個**串流模型**（低延遲）和一個**離線模型**（高準確性），取其長處。
- **典型實現**: [Sherpa-ONNX](https://github.com/k2-fsa/sherpa-onnx) 框架本身就支援 Two-Pass 模式，允許第一階段使用輕量串流模型，第二階段再用高精度離線模型修正。
- **核心技術**:
  1. **第一階段**: 使用一個輕量的原生串流模型（如 Sherpa-ONNX 的 RNN-T）提供即時的初步辨識結果。
  2. **第二階段**: 在工程層面設計一套**觸發邏輯**（基於停頓、標點、句長等），當判斷一句話結束時，將緩存的完整音訊送入未經修改的 Whisper 模型，用其高品質的辨識結果去修正第一階段的輸出。
- **優缺點**:
  - **優點**: **無需訓練模型**，純工程實現，開發成本和資源投入遠低於路線 B 和 C。能同時兼顧低延遲（第一階段）和高準確性（第二階段）。
  - **缺點**: **觸發邏輯的設計是成敗的關鍵和核心難點**。如固定的觸發規則很難完美適應所有說話風格，容易在「太快」和「太慢」之間搖擺。
- **適用場景**: 希望在不投入大量 AI 訓練資源的前提下，快速搭建一個兼顧了低延遲和高準確性的高品質串流系統。

---

## 結論

每條路線都代表了一種在「開發成本」、「延遲體驗」和「辨識準確性」三者之間的權衡。

### 各路線比較總結

| 路線 | 核心思路 | 開發成本 | 延遲體驗 | 準確性 | 文字穩定性 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **A: 偽串流** | 滑動視窗 + 重算 | 低 | 較高 | 高 | 差 (會回退) |
| **B: Encoder+CTC** | 模型微調 | 中 | 中 | 中-高 | 好 (不回退) |
| **C: Encoder+RNN-T**| 模型微調 | 高 | 低 | 高 | 極好 (不回退) |
| **D: Two-Pass** | 雙模型組合 | 中 (純工程) | 低 (Pass 1) | 極高 (Pass 2) | 好 (最終修正) |
